<p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://github.com/introduction_to_cv_and_ml">Computer vision and machine learning</a> by <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://github.com/kzvyagin">Konstantin Zvyagin</a> is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"> <img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a></p>


<h1>Оглавление</h1>

-  Подготовка изображений.
- Введение в работу с изображениями.
- Доступ к произвольному пикселю.
- Общий Список операций над матрицами.
- Функция конвертации изображений с различными типами цветовых каналов.
- Применение фильтров к изображениям.
- Фильтры часть 1. 
  - Проблема рамок	
- Фильтры часть2.
  - Фильтр Гаусса
- Пороговые преобразования.	
- Морфологические преобразования над изображениями.
- Дополнительные морфологические преобразования


<h1>Подготовка изображений </h1>

Подготовка изображений
Как было сказано в предыдущий лекции, большую часть времени тратиться на подготовку данных. В нашем конкретном случае, это на подготовку изображений. Предварительную обработку, понижение размерности, шумоподавления, выделения границ, цветокоррекцию, бинаризацию, сегментирование, и прочие преобразования над изображениями. 

Рассмотрим изображение как один из простых и наглядных материалов. Что из себя представляет изображение. Если мы говорим о изображении в градациях серого или черно-белым то это двумерный массив пикселей. В этом массиве где каждому пикселю соответствует один байт с диапазоном значений 0-255. Часто массив такого справедливо называют матрицей.

Посмотрим на черно-белое и изображение и его численное представление.

![Черно белое изображение 1 ](https://raw.githubusercontent.com/kzvyagin/introduction_to_cv_and_ml/main/chapter2/images/image_1_full.png)

![Черно белое изображение 2 ](https://raw.githubusercontent.com/kzvyagin/introduction_to_cv_and_ml/main/chapter2/images/image_1_1_full.png)



В компьютере двумерный массив NxM (N - количество строк, М - количество столбцов) представлен одномерным массивом размером NxM. При этом обращение к  конкретному пикселю осуществляется элементу строки ,будет выглядеть следующим образом [N\*x+M\*y]. Где x и y соответствуют номер строки и номер колонки в двумерном массиве. 

Мы будем использовать Фреймворк Qt и OpenCV. При понимании базовых принципов обработки изображений Фреймворк уже будет не важен. И вы сможете самостоятельно освоить необходимый. Qt не является Фреймворком для обработки изображений.

<h2>Справка про Qt</h2>

В Qt изображение представлено классом <b>QPixmap</b> и <b>QImage</b>. Отличие следующее:

* класс <b>QPixmap</b> представляет собой представление изображения вне экрана в GUI потоке, которое может использоваться как устройство рисования.
* класс <b>QImage</b> предоставляет аппаратно-независимое представление изображения, которое обеспечивает прямой доступ к данным пикселя и может использоваться как устройство рисования.

Вы не можете манипулировать QPixmap вне GUI-потока, но QImage не имеет таких ограничений.

* Если вы планируете манипулировать изображением, измените его, измените на нем пиксели, и т.д., используйте QImage.
* Если вы планируете нарисовать одно и то же изображение более одного раза на экране преобразуйте его в QPixmap.

Мы будем работать в основном с изображениями в оттенках серого. Для того чтобы упростить работу с изображениями. Перенести алгоритмы и методики на два, три канала можете самостоятельно. Для загрузки можно воспользоваться стандартной библиотекой qt. 


<h2>OpenCV</h2>


OpenCV ( расшифровка англ: Библиотека компьютерного зрения с открытым исходным кодом)-это библиотека программных функций, в основном направленных на компьютерное зрение и обработку изображений в реальном времени. Первоначально библиотека разрабатывалась в российском офисе Intel, позже он был поддержан сообществом Willow Garage, а затем фирмой Itseez (которая позже был приобретен Intel). Библиотека является кроссплатформенной и бесплатной для использования под лицензией Apache 2 с открытым исходным кодом. Начиная с 2011 года, OpenCV имеет ускорение GPU для операций в реальном времени.

В OpenCV для предстваления изображений используется класс cv::Mat.

Класс <b>[cv::Mat](https://docs.opencv.org/4.x/d3/d63/classcv_1_1Mat.html)</b> представляет собой n-мерный числовой однослойный или многослойный массив. Его можно использовать для хранения векторов и матриц реальных или комплексных значений, изображений в оттенках серого или цветных с прозрачностью и без прозрачности, объемов вокселов, векторных полей, облаков точек, тензоров, гистограмм (хотя гистограммы очень высокой размерности лучше хранить в SparseMat). Следует помнить что пиксели в массиве Mat OpenCV хранятся по умолчанию в BGR а не в RGB.

<h1>Введение в работу с изображениями</h1>

Mat [cv::imread( const String & filename, int flags = IMREAD_COLOR ) ](https://docs.opencv.org/4.x/d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56) вернет матрицу изображения.


Изображение представляет собой двумерную матрицу, которая представлена в виде класса cv::Mat. Каждый элемент матрицы представляет собой один пиксель. Для изображений в градациях серого элементы матрицы представлены 8-битными числами без знака (от 0 до 255). Для цветного изображения в формате RGB таких чисел 3, по одному на каждую компоненту цвета. Формат класса cv::Mat следующий.

```
class CV_EXPORTS Mat{
public:        // ... много методов ...        
…
   /*! включает в себя несколько битовых полей:        - сигнатура        - флаг непрерывности        - глубина        - количество каналов        */    
    int flags;  
    int dims;            //! размерность массива, >= 2        
    int rows, cols;      //! количество строк и столбцов или (-1, -1)     
    uchar* data;         //! указатель на данные     
    int* refcount;       //! указатель на счетчик ссылок; когда массив указан        
                         // на выделенные пользователем данные, то указатель равен NULL          
  // другие члены        …
};

```

Данные храниться могут в разных форматах, и это не только 1 и 3 байтные элементы матрицы.

Чтобы показать, как осуществляется запись пикселей, возьмем для примера цветное изображение и выведем поверх него пунктирную белую сетку:

Ромашки исходное изображение

![Ромашки исходный ](https://raw.githubusercontent.com/kzvyagin/introduction_to_cv_and_ml/main/chapter2/images/chamomile_1.png)




Код для реализации этого представлен ниже:

Отобразить на изображении белую пунктирную сетку

```
void drawGrid( cv::Mat &img){
    for (int i = 0; i < img.rows; i++)
    for (int j = 0; j < img.cols; j++)
        if ((i % 20 == 10 && j % 2 == 1) ||                        (j % 50 == 25 && i % 2 == 1))                {
    img.at<cv::Vec3b>(i, j)[0] = 255;
    img.at<cv::Vec3b>(i, j)[1] = 255;
    img.at<cv::Vec3b>(i, j)[2] = 255;
     }
}
...
Mat img = imread("image01.jpg"); // Открытие файла
drawGrid(img)
cv::imshow("Display window", img);


```

Ромашки с сеткой

![Ромашки с сеткой ](https://raw.githubusercontent.com/kzvyagin/introduction_to_cv_and_ml/main/chapter2/images/chamomile_2.png)


Цикл перебирает строки изображения (i) и столбцы (j). Условие вывода на изображения белого пикселя: если остаток от деления на 20 номера строки равен 10 и столбец нечетный, если остаток от деления на 50 номера столбца равен 25 и строка нечетная. Здесь видно, что для вывода белого пикселя закрашивается каждый компонент. Если бы изображение было 8 битным 1 канальным, т.е. градации серого, тогда можно было бы ограничиться одной строкой:

img.at<uchar>(i,j)= 255;

Очевидно, что если есть возможность записывать пиксели, то можно и считывать информацию о них. В следующем примере показано, что каждый пиксель анализируется на принадлежность белого  цвету по порогу. Если пиксель принадлежит белому, то он заменяется на ярко красный цвет.

```
void recolorColor(cv::Mat &img)
{
    for (int i = 0; i < img.rows; i++)
        for (int j = 0; j < img.cols; j++)
    if (     img.at<cv::Vec3b>(i, j)[0] > 220
          && img.at<cv::Vec3b>(i, j)[2] > 220
          && img.at<cv::Vec3b>(i, j)[1] > 220 )
       {
           img.at<cv::Vec3b>(i, j)[0] = 0;
           img.at<cv::Vec3b>(i, j)[1] = 0;
           img.at<cv::Vec3b>(i, j)[2] = 255;
       }
}

Mat img = imread("image01.jpg"); 
recolorColor(img)
imwrite("image01_res2.jpg", img);


```

Ромашки с заменой цвета

![Ромашки с заменой цвета ](https://raw.githubusercontent.com/kzvyagin/introduction_to_cv_and_ml/main/chapter2/images/chamomile_3.png)


<h1>Доступ к произвольному пикселю.</h1>

Использование метода at класса cv::Mat может быть громоздким, поэтому есть несколько способов доступа к произвольному пикселю:
1) Прямая адресация через дополнительные переменные
```
  
    uchar r, g, b;
    for (int i = 0; i < img.rows; ++i)
    {
        cv::Vec3b* pixel = img.ptr<cv::Vec3b>(i); // point to first pixel in row
        for (int j = 0; j < img.cols; ++j)
        {
            r = pixel[j][2];
            g = pixel[j][1];
            b = pixel[j][0];
        }
    }
```
или

```
    uchar r, g, b;
    for (int i = 0; i < img.rows; ++i)
    {
        uchar* pixel = img.ptr<uchar>(i);  // point to first color in row
        for (int j = 0; j < img.cols; ++j)
        {
            b = *pixel++;
            g = *pixel++;
            r = *pixel++;
        }
    }
```
 2) Используя метод at  
```
    uchar r, g, b;
    for (int i = 0; i < img.rows; ++i)
    {
        for (int j = 0; j < img.cols; ++j)
        {
            cv::Vec3b pixel = img.at<cv::Vec3b>(i, j); 
            r = pixel[2];
            g = pixel[1];
            b = pixel[0];
        }
    }


```


При разработке серьезного программного продукта примитивными операциями к конкретному пикселю не обойтись, поэтому необходимо знать существующие операции над матрицами. В данный курс это не входит. Рекомендуем ознакомиться с любым онлайн курсом для студентов по операциям над матрицами. 

<h2>Конструирование Mat</h2>

Не всегда матрицы создаются при открытии изображения из файла или видеопотока. Очень часто приходится создавать изображения самостоятельно для этого в классе cv::Mat различные конструкторы, например, следующие:
```

Mat::Mat(int rows, int cols, int type);
Mat::Mat(Size size, int type);
```
Здесь <b>Size</b> – это класс из пространства имен cv, которым можно задавать размеры матрицы, например, так:
```
Mat mat(Size(200, 200), CV_8UC1);
```

<b>CV_8UC1</b> – означает тип изображения: 8-битное 1 канальное unsigned char. Типы матриц определяются по следующей формуле:
 <b>CV_<S|U|F>C</b> где:
 * bit depth характеризует количество бит на глубину. 
 * S=signed, U=unsigned, 
 * F=float. 
 * А number of channels – количество каналов.

 Удалять изображение не надо, поскольку в конце области видимости, где определена матрица, будет вызван деструктор для Mat или когда счетчик ссылок на матрицу становится равным нулю. Важно помнить, что следующая строка
<b>
```
Mat mat2 = mat;
```
</b>

<b>не осуществляет копирование матрицы</b>, а лишь увеличивает счетчик ссылок на матрицу. 

Для того, чтобы матрицу скопировать нужно вызвать метод <b>copyTo( см пример )</b> или <b>A.clone()</b>.


Нарисуем прямоугольник на нашем новом буфере 
```
    cv::Mat mat3(cv::Size(img.cols , img.rows), CV_8UC3); // TODO помни что надо type спросить у  основного изображения
    mat3.setTo(cv::Scalar(0,0,0));
    cv::rectangle(mat3,cv::Rect(100,100,100,100),cv::Scalar(0,0,255),3);
    cv::imshow("Display window1", mat3    );
```

Над матрицами можно осуществлять действия без вызова функций, например проводить математические операции матрицы с числом и матрицы с матрицей. 

Далее приведен пример математических операций над матрицами.

```
    Mat img = imread("image01.jpg"); // Открытие файлаMat img2;img.copyTo(img2);
    img2 = img2 * 2; // Увеличение яркости в 2 раза
    imwrite("image01_res3.jpg", img2);
    Mat img3;
    img.copyTo(img3);
    img3 = img3 * 0.25; // Уменьшение яркости в 4 разаimwrite("image01_res4.jpg", img3);
 ```

![Ромашки с увеличением яркости ](https://raw.githubusercontent.com/kzvyagin/introduction_to_cv_and_ml/main/chapter2/images/chamomile_4.png)

![Ромашки с уменьшением яркости ](https://raw.githubusercontent.com/kzvyagin/introduction_to_cv_and_ml/main/chapter2/images/chamomile_5.png)

Если необходимо объединить изображения, то это очень просто. Пример представлен ниже :

```
 void drawRectAndShowWithSource(cv::Mat imgSrg)
{
    cv::Mat img;
    imgSrg.copyTo(img);
    cv::Mat mat3(cv::Size(img.cols, img.rows), img.type());
    mat3.setTo(cv::Scalar(0,0,0));
    cv::rectangle(mat3,cv::Rect(100,100,100,100),cv::Scalar(0,0,255),3);
    cv::imshow("RECT1", mat3    );
    cv::Mat img2;
    cv::addWeighted( img, 1, mat3, 1, 0.0, img2);
   // img=mat3+img;
    cv::imshow("Display window2", img2);
}
```

![Квадрат для объединения ](https://raw.githubusercontent.com/kzvyagin/introduction_to_cv_and_ml/main/chapter2/images/chamomile_6.png)

![Ромашки с объединением с квадратом ](https://raw.githubusercontent.com/kzvyagin/introduction_to_cv_and_ml/main/chapter2/images/chamomile_7.png)


Это далеко не все операции над матрицами, поэтому далее приведены возможные операции с матрицами.


Общий Список операций над матрицами:
которые могут быть использованы в произвольно сложных выражениях(A, B – матрицы, s – скаляр, alpha – вещественный скаляр) :

    • сложение, вычитание, 	отрицание : A + B, A — B, A + s, A — s, s + A, s — A, 	-A; 	
    • управление яркостью : 	A*alpha; 	
    • поэлементное 	умножение / деление: A.mul(B), A / B, alpha / A; 
    • умножение матриц 	: A*B; 
    • транспонированная 	матрица : A.t(); 	
    • обращение матрицы 	и псевдо — инверсии, решения линейных 	систем и наименьших квадратов : 	A.inv([метод]), A.inv([метод])*B; 	
    • сравнивание : A op B, 	A op alpha, alpha op A, где op это одно из следующих 	: >, >= , == , != , <= , <.Результат сравнения 	в одноканальной 8 — битной матрице; 	
    • битовые логические 	операции : A op B, A op s, s op A, ~A, где op это одно 	из следующих : &, | , ^; 	
    • нахождение минимума 	/ максимума: min(A, B), min(A, alpha), max(A, B), max(A, 	alpha); 	
    • abs(A); 	
    • векторное и скалярное 	произведение : A.cross(B) A.dot(B); 	
    • любая функция матрицы или матриц, 	которая возвращает скаляр, например, 	norm, mean, sum, countNonZero, trace, determinant, repeat. 


Функция конвертации изображений с различными типами цветовых каналов:
Наиболее часто востребованная функция cvtColor предназначена для конвертации матриц изображений с различным цветовым пространством.
Рассмотрим ее подробнее

```
void cvtColor(        InputArray src,        OutputArray dst,        int code,        int dstCn = 0);
```
Параметры:


```
• src – входная матрица; 
• dst – выходная 	матрица, размер матрицы должен быть 	таким же, как и в src; 	
• code – код конвертации; 		
• dstCn – количество 	каналов в конечной матрице, если указано 	0, то количество каналов определяется 	автоматически. 	
```

Функция cvtColor 	преобразует изображение представленное в виде матрицы  из одного цветового пространства, в другое, тип преобразование задаться параметром code. 

Внимание: Цветовой формат в OpenCV 	по умолчанию не RGB, а BGR! 	

Обычные диапазоны значений цветов  R, G и B в различных цветовых пространствах :


    • 0 — 255 для CV_8U 	изображений, 	
    • 0 — 65535 для CV_16U 	изображений, 	
    • 0 — 1 для CV_32F изображений. 	


В случае линейных преобразований, диапазон не имеет значения. Но в случае нелинейной трансформации, входное RGB изображение должно быть нормализовано для надлежащего диапазона значений, чтобы получить правильные результаты (см. Документацию).


Функция поддерживает следующие трансформации :


    • RGB в GRAY и обратно – 	CV_BGR2GRAY, CV_RGB2GRAY, CV_GRAY2BGR, CV_GRAY2RGB; 	
    • RGB в CIE XYZ.Rec 709 (и 	обратно) – CV_BGR2XYZ, CV_RGB2XYZ, CV_XYZ2BGR, CV_XYZ2RGB; 	
    • RGB в YCrCb JPEG(YCC) (и 	обратно) – CV_BGR2YCrCb, CV_RGB2YCrCb, CV_YCrCb2BGR, 	CV_YCrCb2RGB; 	
    • RGB в HSV(и обратно) – 	CV_BGR2HSV, CV_RGB2HSV, CV_HSV2BGR, CV_HSV2RGB; 	
    • RGB в HLS(и обратно) – 	CV_BGR2HLS, CV_RGB2HLS, CV_HLS2BGR, CV_HLS2RGB; 	
    • RGB в CIE L*a*b* (и обратно) 	– CV_BGR2Lab, CV_RGB2Lab, CV_Lab2BGR, CV_Lab2RGB; 	
    • RGB в CIE L*u*v* (и обратно) 	– CV_BGR2Luv, CV_RGB2Luv, CV_Luv2BGR, CV_Luv2RGB; 	
    • Bayer в RGB – CV_BayerBG2BGR, CV_BayerGB2BGR,  CV_BayerRG2BGR, CV_BayerGR2BGR, CV_BayerBG2RGB, CV_BayerGB2RGB, 	CV_BayerRG2RGB, CV_BayerGR2RGB. 	




Пример вызова :
```
cvtColor(Image24, Gray, CV_BGR2GRAY);

```
Здесь показан перевод из RGB 24 — битного изображения в 8 — битное градаций серого.



<h1>Применение фильтров к изображениям.</h1>
<h2>Фильтры часть 1.</h2>

Рассотрим следующие понятия  «фильтр», «ядро», «свертка», «якорь».  Пусть мы имеем некоторое изображение представленное в виде матрицы I1 . Наша задача – изменить данное изображение и получить новое: I2. Причем каждый пиксель нового изображения I2(x, y) должен получать свое значение в зависимости от значения пикселей некоторой окрестности пикселя с теми же координатами на старом I1(x, y).
Получается, что мы имеем алгоритм, который получает на вход изображение I1 и возвращает новое изображение I2, при этом пересчитав значения каждого пикселя I2(x, y) путем комбинирования пикселей окрестности I1(x, y). Способ комбинирования пикселей и размер окрестности – основа данного алгоритма. Сочетание этих двух элементов и является фильтром. В контексте обработки изображений фильтр также иногда называют ядром. Здесь эти термины взаимозаменяемы. Разница будет заключаться только в том, что термин «фильтр» чаще употребляется в контексте обработки сигналов, а термин «ядро» – в математике. Итак, пиксели изображения I2 зависят от пикселей изображения I1. Если эта зависимость линейная, то изображение I2 получено из изображения I1 с применением линейного фильтра. И, очевидно, если зависимость нелинейная, то для получения изображения I2 к изображению I1 применялся нелинейный фильтр. Многие фильтры, которые часто применяются при обработке изображений, являются именно линейными фильтрами. Поэтому подробнее разберем, какие вычисления производятся при применении линейного фильтра. Если к изображению I1 применяется линейный фильтр, то значение каждого пикселя изображения I2(x, y) можно выразить в виде взвешенной суммы окрестностей пикселя I1(x, y). Это можно записать в виде формулы (1.1):


![ Формула 1.1 ](https://raw.githubusercontent.com/kzvyagin/introduction_to_cv_and_ml/main/chapter2/images/formula_1.1.png)





где K – фильтр, представленный в виде матрицы; h – высота матрицы (число строк); w – ширина матрицы (число столбцов); I1 и I2 – входное и выходное изображения; (x, y) – координаты пикселя, относительно которого выполняются вычисления.

Если фильтр можно записать таким образом, то он будет линейным. Линейные фильтры также называют свертками. В контексте технического зрения термин «свертка» иногда употребляется по отношению к любым фильтрам вне зависимости от того, линейные они или нет.

Для лучшего понимания того, что такое фильтр, удобно представить его
графически в виде массива. На рис. 1.1 изображено графическое представление двух типичных фильтров размера 5 на 5 пикселей.


![ Прямоугольный фильтр и фильтр Гаусса ](https://raw.githubusercontent.com/kzvyagin/introduction_to_cv_and_ml/main/chapter2/images/filter_1.png)

Рисунок 1.1. Прямоугольный фильтр (слева) и фильтр Гаусса (справа). Кружком выделен пиксель который считается на основе всего окна фильтра. 


И у прямоугольного фильтра, и у фильтра Гаусса на рис. 1.1 есть особенный элемент – якорная точка (выделен зеленым кругом). Здесь это центральные элементы, которые на рисунке обведены в круг. Якорная точка определяет то, как именно фильтр будет накладываться на изображение. Мы помним, что фильтр применяется к каждому пикселю изображения. Якорная точка – это та точка фильтра, которая накладывается на точку I1(x, y) при расчете значения пикселя I2(x, y). Если якорная точка находится посередине, при расчете нового значения I2(x, y) учитывается одинаковое число пикселей во всех направлениях окрестности. На рис. 2.1 представлены ненормированные варианты прямоугольного фильтра и фильтра Гаусса. При применении таких фильтров значение пикселей нового изображения будет увеличиваться. Причем чем больше размер ядра, тем больше пикселей и коэффициентов будут участвовать в суммировании и тем больше будет увеличение. Существует также вариант применения нормирова ных ядер. В этом случае все значения матрицы будут делиться на сумму элементов матрицы. Например, сумма элементов ненормированного фильтра Гаусса размера 5 на 5 пикселей равна 273 При расчете I2(x, y) пиксель I1(x, y) будет умножен на 41/273, пиксель I1(x+1, y) – на 26/273, пиксель I1(x+2, y) – на 7/273 и так далее. Теперь разберем, как изменится изображение, если применить фильтр не к одному пикселю, а к каждому пикселю изображения. На рис. 1.2 изображено применение некоторого фильтра размера 3 на 3 к изображению 5 на 5 пикселей.

![ Применение фильтра ](https://raw.githubusercontent.com/kzvyagin/introduction_to_cv_and_ml/main/chapter2/images/filter_2.png)

Рисунок 1.2.  Применение фильтра. Исходное изображение (слева), фильтр (по центру )б результат применения (справа) . 

К исходному изображению 5 на 5 пикселей применяется фильтр размером 3 на 3 Якорная точка в нашем случае – средняя точка фильтра. Будем накладывать фильтр на изображение, начиная с левого верхнего угла. При этом нужно наложить фильтр так, чтобы вся матрица покрывала существующие пиксели изображения. На рис. 1.2, а продемонстрировано, как будет наложен фильтр на первом шаге. Если верхний левый пиксель изображения имеет координаты (0, 0), то якорная точка для фильтра размером 3 на 3 будет наложена на пиксель с координатами (1, 1). Новое значение для данного пикселя изображения будет равно 12 Оно выделено на рис. 1.2, в. Очевидно, что значение для точки (0, 0) исходного изображения не может быть пересчитано: за границами изображения отсутствуют пиксели, на которые будет наложен фильтр. То же верно для всех пикселей исходного изображения, которые примыкают к границам. Очевидно, что простое применение фильтра без дополнительных мер приводит к уменьшению размера изображения. При этом чем больше фильтр, тем меньше будет новое изображение.

<h2>Проблема рамок</h2>

При ручной обработке, для того чтобы иметь возможность при применении фильтра к изображению не уменьшать его размер, можно дополнить изображение пикселями на границах – создать рамку. На рис. 1.3 приведен пример добавления рамки к изображению. Можно так-же пожертвовать частью изображения на краях.

![ Добавление рамки ](https://raw.githubusercontent.com/kzvyagin/introduction_to_cv_and_ml/main/chapter2/images/border_1.png)

Рисунок 1.3.  Процесс добавления рамки к изображению. Слева исходное изображение, справа изображение с рамкой. 


На изображении 1.3, б к исходному изображению добавлена рамка шириной в 1 пиксель. Единственно верного способа задания значения пикселям, которые принадлежат рамке, не существует. В OpenCV, например, существует несколько разных способов выбора значений как в зависимости от содержимого изображения, так и нет. Вне зависимости от того, какие значения заполняют область рамки, она позволяет применять фильтры, совмещая якорную точку с пикселем на границе. На рис. 1.4 изображен пример наложения фильтра размера 3 на 3 на изображение с рамкой.


![ Применение фильтра с рамкой ](https://raw.githubusercontent.com/kzvyagin/introduction_to_cv_and_ml/main/chapter2/images/filter_3.png)

Рисунок 1.4.  Применение фильтра к изображению с рамкой. Слева фильтр , справа применение фильтра к изображению с рамкой . 


В OpenCv есть для этого специальная функция 

```
copyMakeBorder(
    InputArray src, /* входное изображение */
    OutputArray dst,
    int top, int bottom, int left, int right, /* задается рамка в пикселях */
    int borderType, # тип рамки 
    const Scalar& value = Scalar() /*тип заливки рамки*/ ) ;
```

Поэкспериментировать с ней можете самостоятельно.

Далее вернёмся к фильтрам.

<h2>Фильтры часть2.</h2>


Итак, сглаживание, или размытие, довольно часто встречается на этапе обработки изображений, поскольку позволяет удалить шумы и улучшить результат работы алгоритмов. Поэтому разберем, как можно реализовать такую операцию средствами OpenCV.
Самый простой вариант размытия реализован в OpenCV в виде функции blur().
```
img_new = cv2.blur(
	img, // входное изображение
	ksize, // размер ядра
	anchor, // положение якорной точки
	bType, // тип рамки
)
```

Такой фильтр вычисляет для каждого пикселя нормированное среднее значение по всем пикселям. В аргумент img передается входное изображение. Размер фильтра (ядра) задается во втором аргументе – ksize. В этот аргумент нужно передать кортеж из двух элементов – ширины и высоты фильтра.

Положение якорной точки можно указать, передав его в аргумент anchor. По умолчанию якорная точка находится в центре фильтра. Тип границы можно передать в аргумент bType, если имеется необходимость изменить тип по умолчанию – cv2.BORDER_DEFAULT – на какой-либо другой. Значение cv2.BORDER_WRAP не поддерживается. Возвращаемое значение функции новое изображение. Функцию можно применять как к одноканальным, так и к многоканальным изображениям. Во втором случае каждый канал обрабатывается отдельно.

Данная функция является частным случаем прямоугольного фильтра, который в OpenCV реализован в функции boxFilter().

```
img_new = cv2.boxFilter(
	img,       // входное изображение
	ddepth,    // глубина изображения-результата
	ksize,     // размер ядра
	anchor,    // положение якорной точки
	normalize, // нормирование (если True)
	bType      // тип рамки
)
```

Прямоугольным называется такой фильтр, все элементы которого равны. Аргументы img, ksize, anchor и bType соответствуют одноименным аргументам функции blur(). Наличие аргумента ddepth – первое отличие функции boxFilter() от функции blur(). В функции blur() глубина выходного изображения совпадает с глубиной входного. Такое же поведение будет у функции boxFilter(), если передать в этот аргумент значение -1 При необходимости можно указать любое другое поддерживаемое значение глубины. Данный фильтр может быть нормированным и ненормированным. Этот параметр регулируется аргументом normalize: нормированный, если значение аргумента – True, и ненормированный, если значение аргумента – False. По умолчанию аргумент имеет значение True. В первом случае значение каждого элемента будет делиться на площадь фильтра, то есть сумму его элементов. Пример ненормированного прямоугольного фильтра уже приводился, например, на рис. 2.1, а. Для прямоугольного фильтра размером 5 на 5, все элементы которого равны 1, нормирование будет осуществляться делением каждого элемента на 25

<i>Теперь время практики, необходимо поэкспериментировать с изображениями.</i>

Среди фильтров, позволяющих осуществить сглаживание изображения, существует также один пример нелинейного фильтра – медианный фильтр. При применении этого фильтра значения пикселя заменяются на медианное значение,а не на среднее арифметическое. Для каждого пикселя рассматриваются значения внутри прямоугольной области, которая определяется размером фильтра.

Достоинством медианного фильтра перед прямоугольным является способность игнорировать выбросы – пиксели, значения которых сильно отличаются от соседних. В случае с расчетом среднего арифметического их значения могут оказать существенное влияние на результат. Так как в медианном фильтре выбирается точка со средним значением, такие выбросы на результат не влияют. В OpenCV медианный фильтр можно применить с помощью функции medianBlur().

```
img_new = cv2.medianBlur(
	img,  // входное изображение
	ksize // размер ядра
)
```


Единственная пара параметров, которые можно указать для этой функции – входное изображение и размер ядра. Входное изображение задается так же, как для других фильтров – передается в аргумент img. А вот задание размера ядра отличается. В аргумент ksize здесь нужно передать не кортеж из двух элементов, а целое число. Возвращаемое значение функции – новое изображение. Результат применения данного фильтра к тому же набору изображений представлен на рис. 1.5.

![ Результат применения фильтра blur. ](https://raw.githubusercontent.com/kzvyagin/introduction_to_cv_and_ml/main/chapter2/images/bluer_1.5.png)

Рисунок 1.5. Результат применения фильтра blur, слева исходное изображение, справа изображение с применением фильтра blur. 


<h3>Фильтр Гаусса</h3>

На практике для сглаживания часто применяются фильтры на основе нор-
мального распределения. Одним из наиболее популярных способов сглаживания изображения является фильтр Гаусса. Для каждого пикселя вычисляется взвешенное среднее значение самого пикселя и его соседей. Веса в функции зависят от расстояния между центральным пикселем и соответствующим соседним.
В OpenCV он реализован в функции GaussianBlur(). При применении данной функции будет использовано нормированное ядро.

```
img_new = cv2.GaussianBlur(
	img,    // входное изображение
	ksize,  // размер ядра
	sigmaX, // сигма по оси X
	sigmaY, // сигма по оси Y
	bType   // тип рамки
)
```
Аргументы img, ksize и bType совпадают с одноименными аргументами для функций blur() и boxFilter().


Величина сигмы влияет на то, какие соседи имеют больший вес. Чем больше сигма, тем больше вес удаленных точек и тем меньше вес центральных. Ядро в некотором смысле «растягивается», более равномерно распределяя веса по всем соседям. Если же значение сигмы маленькое, то точки около центра ядра будут иметь очень большое значение, а удаленные от центра точки будут иметь вес, практически равный нулю. Можно отдельно задавать сигму для расстояний по оси X и по оси Y. Примеры ядер для разных параметров сигма можно увидеть на рис. 1.6. Для выбора одинаковых значений параметров сигма не обязательно задавать значения в оба аргумента – sigmaX и sigmaY. В случае если sigmaY равно 0, этот параметр выбирается равным sigmaX.


![ Ядра для разных параметров сигма. ](https://raw.githubusercontent.com/kzvyagin/introduction_to_cv_and_ml/main/chapter2/images/gauss_core_1.6.png)

Рисунок 1.6. Ядра для разных параметров сигма. 

В случае если в оба аргумента передать значения 0, расчет значений будет
выполняться по формуле 2.5:





to bo continued ...